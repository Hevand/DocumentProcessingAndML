{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Connect to your workspace\n",
        "Below steps taken from: [Microsoft docs: Deploy your ML model](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-and-where?tabs=python)\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "from azureml.core import Workspace, Dataset\n",
        "ws = Workspace.from_config()"
      ],
      "outputs": [],
      "metadata": {
        "gather": {
          "logged": 1632812336005
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (Create / obtain and) Set the model\r\n",
        "\r\n",
        "    For now, this model will not actively be used. Instead, the score.py will download the model JIT.\r\n",
        "    In later iterations, this code can be used to set the 'model' variable to an existing model in the workspace. At that time, make sure to update the score.py as well."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import urllib.request\n",
        "from azureml.core.model import Model\n",
        "\n",
        "# Download model\n",
        "urllib.request.urlretrieve(\"https://aka.ms/bidaf-9-model\", \"model.onnx\")\n",
        "\n",
        "# Register model\n",
        "model = Model.register(ws, model_name=\"bidaf_onnx\", model_path=\"./model.onnx\")"
      ],
      "outputs": [],
      "metadata": {
        "gather": {
          "logged": 1632750214624
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a web service around the model\r\n",
        "\r\n",
        "- Create a runtime environment (using the conda configuration with any dependencies)\r\n",
        "- Define a wrapping script to act as the initialization and entry point for any incoming request (score.py)\r\n",
        "- Create a local service (on the associated compute) to build the container and test the results"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "source": [
        "from azureml.core import Environment\n",
        "from azureml.core.model import InferenceConfig\n",
        "\n",
        "env = Environment(name=\"project_environment\").from_conda_specification(name = \"lease-abstract\", \n",
        "                              file_path = \"../config/inference-conda.yml\")\n",
        "\n",
        "inference_config = InferenceConfig(\n",
        "    environment=env,\n",
        "    source_directory=\"../\",\n",
        "    entry_script=\"./score.py\",\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "gather": {
          "logged": 1632750682807
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "source": [
        "from azureml.core.webservice import LocalWebservice\n",
        "\n",
        "deployment_config = LocalWebservice.deploy_configuration(port=10002)"
      ],
      "outputs": [],
      "metadata": {
        "gather": {
          "logged": 1632497302771
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "service = Model.deploy(\n",
        "    ws,\n",
        "    \"leaseabstractservice\",\n",
        "    [model],\n",
        "    inference_config,\n",
        "    deployment_config,\n",
        "    overwrite=True,\n",
        ")\n",
        "service.wait_for_deployment(show_output=True)"
      ],
      "outputs": [],
      "metadata": {
        "gather": {
          "logged": 1632492562061
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(service.get_logs())"
      ],
      "outputs": [],
      "metadata": {
        "gather": {
          "logged": 1632490825428
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the local service"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "uri = service.scoring_uri\n",
        "requests.get(\"http://localhost:10002\")\n",
        "headers = {\"Content-Type\": \"application/json\"}\n",
        "data = {\n",
        "    \"id\": \"123456789\",\n",
        "    \"content\": \"The quick brown fox jumped over the lazy dog.\",\n",
        "}\n",
        "data = json.dumps(data)\n",
        "response = requests.post(uri, data=data, headers=headers)\n",
        "print(response.json())"
      ],
      "outputs": [],
      "metadata": {
        "gather": {
          "logged": 1632492673266
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deploy the model to the target compute\r\n",
        "In this demo, we will use Azure Container Instances (as they're easier to setup and appropriate for initial experimentation). In production / at scale, the use of AKS is recommended.\r\n",
        "\r\n",
        "The document linked at the beginning of this article describes how to use alternative deployment options."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from azureml.core.webservice import AciWebservice\n",
        "\n",
        "deployment_config = AciWebservice.deploy_configuration(cpu_cores=2, memory_gb=4, auth_enabled=True)\n",
        "\n",
        "service = Model.deploy(ws, \"leaseabstractservice\", [model], inference_config, deployment_config, overwrite=True)\n",
        "\n",
        "service.wait_for_deployment(show_output=True)"
      ],
      "outputs": [],
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(service.get_logs())"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Invoke the Aci-hosted web service."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import requests\n",
        "import json\n",
        "from azureml.core import Webservice\n",
        "\n",
        "service = Webservice(workspace=ws, name=\"leaseabstractservice\")\n",
        "scoring_uri = service.scoring_uri\n",
        "\n",
        "# If the service is authenticated, set the key or token\n",
        "key, _ = service.get_keys()\n",
        "\n",
        "# Set the appropriate headers\n",
        "headers = {\"Content-Type\": \"application/json\"}\n",
        "headers[\"Authorization\"] = f\"Bearer {key}\"\n",
        "\n",
        "# Make the request and display the response and logs\n",
        "data = {\n",
        "    \"id\": \"MyContent\",\n",
        "    \"content\": \"The quick brown fox jumped over the lazy dog.\",\n",
        "}\n",
        "data = json.dumps(data)\n",
        "resp = requests.post(scoring_uri, data=data, headers=headers)\n",
        "print(resp.text)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}